{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyspark in c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages (3.5.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages (from pyspark) (0.10.9.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Assesment').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Number of New Users in January 2024: Count of users who joined in January 2024.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+----------+\n",
      "|user_id|user_name| join_date|\n",
      "+-------+---------+----------+\n",
      "|    101|    Alice|2023-05-10|\n",
      "|    102|      Bob|2023-06-15|\n",
      "|    103|  Charlie|2023-07-20|\n",
      "|    104|     Dana|2023-08-25|\n",
      "|    105|    Emily|2023-09-30|\n",
      "+-------+---------+----------+\n",
      "\n",
      "Count of user in January 2024 : 0 \n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, month, year\n",
    "user_data=spark.read.csv('Users.csv',header=True,inferSchema=True)\n",
    "user_data.show()\n",
    "\n",
    "\n",
    "# filter users who join in Jan 2024\n",
    "user_jan_24 = user_data.filter((year(col('join_date')) == 2024) & (month(col('join_date')) == 1))\n",
    "\n",
    "print(f'Count of user in January 2024 : {user_jan_24.count()} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Monthly Active Users (MAU) for January 2024: Count of unique users active in January\n",
    "2024.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monthly Active User for January 2024 :5\n"
     ]
    }
   ],
   "source": [
    "user_activity_df=spark.read.csv('UserActivity.csv',header=True,inferSchema=True)\n",
    "#user_activity_df.show()\n",
    "user_activity_df_24 = user_activity_df.filter((year(col('activity_date')) == 2024) & (month(col('activity_date')) == 1))\n",
    "#user_activity_df_24.show()\n",
    "user_activity_df_24_unique=user_activity_df_24.select('user_id').distinct().count()\n",
    "print(f'Monthly Active User for January 2024 :{user_activity_df_24_unique}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Total Sales Revenue for January 2024: Sum of sales in January 2024.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sales revenue for January 2024: 700.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum as spark_sum\n",
    "sales_df=spark.read.csv('Sales.csv',header=True,inferSchema=True)\n",
    "#sales_df.show()\n",
    "\n",
    "\n",
    "\n",
    "df_filtered = sales_df.filter((year(col('sale_date')) == 2024) & (month(col('sale_date')) == 1))\n",
    "\n",
    "# Sum the sales_amount for jan 2024\n",
    "total_sales_revenue = df_filtered.agg(spark_sum('amount').alias('total_sales_revenue')).collect()[0]['total_sales_revenue']\n",
    "\n",
    "print(f'Total sales revenue for January 2024: {total_sales_revenue}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Average Sale Amount Per Category for January 2024:Average sale amount per category in\n",
    "January 2024.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Sale Amount Per Category for Jan 2024 :\n",
      "+-----------+----------------+\n",
      "|category_id|avg_sales_amount|\n",
      "+-----------+----------------+\n",
      "|         C3|           200.0|\n",
      "|         C1|           100.0|\n",
      "|         C2|           150.0|\n",
      "+-----------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import  avg\n",
    "\n",
    "sales_df=spark.read.csv('Sales.csv',header=True,inferSchema=True)\n",
    "\n",
    "# filter data for jan 2024\n",
    "sales_df_24 = sales_df.filter((year(col('sale_date')) == 2024) & (month(col('sale_date')) == 1))\n",
    "\n",
    "# Calculate average sale amount per category\n",
    "avg_sales_per_categ= sales_df_24.groupBy('category_id').agg(avg('amount').alias('avg_sales_amount'))\n",
    "print(\"Average Sale Amount Per Category for Jan 2024 :\")\n",
    "# Show the result\n",
    "avg_sales_per_categ.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Top Selling Product Category in January 2024: Product category with highest sales in\n",
    "January 2024.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Selling Product Category in January 2024: Clothing with total sales of $300.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sales_df=spark.read.csv('Sales.csv',header=True,inferSchema=True)\n",
    "categories_df=spark.read.csv('Categories.csv',header=True,inferSchema=True)\n",
    "\n",
    "\n",
    "# Filter data for January 2024\n",
    "sales_df_filtered = sales_df.filter((year(col('sale_date')) == 2024) & (month(col('sale_date')) == 1))\n",
    "\n",
    "# Calculate total sales per category\n",
    "total_sales_per_category = sales_df_filtered.groupBy('category_id').agg(spark_sum('amount').alias('total_sales'))\n",
    "\n",
    "# Join with categories table to get category names\n",
    "result_df = total_sales_per_category.join(categories_df, on='category_id', how='inner')\n",
    "\n",
    "# Find the top-selling category\n",
    "top_selling_category = result_df.orderBy(col('total_sales').desc()).first()\n",
    "\n",
    "print(f\"Top Selling Product Category in January 2024: {top_selling_category['category_name']} with total sales of ${top_selling_category['total_sales']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
